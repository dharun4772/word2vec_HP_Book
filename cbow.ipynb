{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import contractions\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: C:\\Users\\surya\\.cache\\kagglehub\\datasets\\shubhammaindola\\harry-potter-books\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shubhammaindola/harry-potter-books\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 Harry Potter and the Sorcerers Stone.txt\n",
      "02 Harry Potter and the Chamber of Secrets.txt\n",
      "03 Harry Potter and the Prisoner of Azkaban.txt\n",
      "04 Harry Potter and the Goblet of Fire.txt\n",
      "05 Harry Potter and the Order of the Phoenix.txt\n",
      "06 Harry Potter and the Half-Blood Prince.txt\n",
      "07 Harry Potter and the Deathly Hallows.txt\n"
     ]
    }
   ],
   "source": [
    "contents = os.listdir(path)\n",
    "for item in contents:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_text = \"\"\n",
    "for item in contents:\n",
    "    with open(f\"C:/Users/surya/.cache/kagglehub/datasets/shubhammaindola/harry-potter-books/versions/1/{item}\") as f:\n",
    "        text = f.read()\n",
    "    overall_text +=\"\\n\"+text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6285445"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overall_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\surya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    replacer = str.maketrans('','',string.punctuation)\n",
    "    text = text.translate(replacer)\n",
    "    text = contractions.fix(text)\n",
    "    text = text.replace(\",\",\"\")\n",
    "    text = text.replace(\"—\",\"\")\n",
    "    text = text.replace(\"-\",\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace(\"\\\"\",\"\")\n",
    "    text = text.replace(\"”\",\"\")\n",
    "    text = text.replace(\"“\",\"\")\n",
    "    text = text.replace(\"’\",\"\")\n",
    "    print(f\"Before removing stopwords: {len(text)}\")\n",
    "    text = \" \".join([element for element in text.split() if random.random() <= 0.6 or element not in stopwords.words(\"english\")])\n",
    "    print(f\"After removing stopwords: {len(text)}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing stopwords: 6042053\n",
      "After removing stopwords: 5177267\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = preprocess(overall_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed.txt', 'w') as file:\n",
    "    file.write(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequence = preprocessed_text.split()\n",
    "vocab = set()\n",
    "d={}\n",
    "for word in word_sequence:\n",
    "    if word in d:\n",
    "        d[word]+=1\n",
    "        if d[word]>=5 and word not in vocab:\n",
    "            vocab.add(word)\n",
    "    else:\n",
    "        d[word]=1\n",
    "\n",
    "\n",
    "vocab_d = {}\n",
    "for i, val in enumerate(vocab):\n",
    "    vocab_d[val] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequence_new = [word for word in word_sequence if word in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = []\n",
    "context_size = 10\n",
    "for i in range(1, len(word_sequence_new)-1):\n",
    "    if word_sequence_new[i] in vocab_d:\n",
    "        inp = vocab_d[word_sequence_new[i]]\n",
    "        context = []\n",
    "        for j in range(context_size):      \n",
    "            if i-j+1>=0:\n",
    "                context.append(vocab_d[word_sequence_new[i-j+1]])\n",
    "            if i+j+1<=context_size:\n",
    "                context.append(vocab_d[word_sequence_new[i+j+1]])\n",
    "        for w in context:\n",
    "            cbow.append([w, inp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
